# -*- coding: utf-8 -*-
"""Cybria_Fed_Model_Test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/xxx
"""

import numpy as np
import tensorflow as tf
import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Step 1: Load and preprocess the datasets
def preprocess_dataset(file_path):
    dataset = pd.read_csv(file_path)
    # Preprocess the dataset as needed (e.g., data cleaning, feature engineering, etc.)
    # Example: dataset = dataset.dropna() to handle missing values
    return dataset

# Step 2: Define the model architecture
num_features = 18  # Update with the correct number of features
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(num_features,)),  # Add dummy input layer
    # Define your layers here
    # e.g., tf.keras.layers.Dense(units=..., activation=...)
])

# Define a custom model class that inherits from tf.keras.models.Model
class CustomModel(tf.keras.models.Model):
    def __init__(self, model):
        super(CustomModel, self).__init__()
        self.model = model

    def average_weights(self, client_weights):
        averaged_weights = []
        for weights_list in zip(*client_weights):
            averaged_weights.append(np.mean(weights_list, axis=0))
        return averaged_weights

    def call(self, inputs):
        return self.model(inputs)

# Step 3: Define the Federated Learning process
def create_model():
    return CustomModel(model)

def create_optimizer():
    return tf.keras.optimizers.SGD(learning_rate=0.01)

class Server:
    def __init__(self, model, optimizer):
        self.model = model
        self.optimizer = optimizer

    def train_on_clients(self, clients):
        for client in clients:
            client.train(self.model)

    def aggregate_weights(self, client_weights):
        averaged_weights = self.model.average_weights(client_weights)
        self.model.set_weights(averaged_weights)

class Client:
    def __init__(self, dataset):
        self.model = create_model()
        self.dataset = dataset
        self.encoder = LabelEncoder()

    def train(self, server_model):
        self.model.set_weights(server_model.get_weights())
        self.model.compile(optimizer=create_optimizer(), loss='sparse_categorical_crossentropy')
        # Perform training on a fraction of the client's dataset
        fraction = 0.5  # Adjust the fraction based on available resources
        subset = self.dataset.sample(frac=fraction)
        x_train = subset.drop('category', axis=1)

        # Apply label encoding to each column
        for column in x_train.columns:
            x_train[column] = self.encoder.fit_transform(x_train[column])

        y_train = subset['category']

        # Apply label encoding to the target
        y_train_encoded = self.encoder.fit_transform(y_train)

        batch_size = 16  # Reduce the batch size to conserve memory
        num_batches = len(x_train) // batch_size
        for batch in range(num_batches):
            start = batch * batch_size
            end = start + batch_size
            x_batch = x_train.iloc[start:end]
            y_batch = y_train_encoded[start:end]
            self.model.train_on_batch(x_batch.values.reshape(-1, num_features).astype(np.float32), y_batch)
        del subset, x_train, y_train_encoded  # Delete temporary variables to free up memory

def create_clients(file_paths):
    clients = []
    for file_path in file_paths:
        dataset = preprocess_dataset(file_path)
        client = Client(dataset)
        clients.append(client)
    return clients

# Step 4: Initialize the server and clients
server_model = create_model()
server_optimizer = create_optimizer()
server = Server(server_model, server_optimizer)

file_paths = ['/content/train_A.csv', '/content/train_B.csv', '/content/train_C.csv']  # Update with the correct file paths
clients = create_clients(file_paths)

# Step 5: Run the Federated Learning process
num_rounds = 2 #2 for testing/demo
for round_num in range(num_rounds):
    # Train the clients on their respective datasets
    server.train_on_clients(clients)

    # Retrieve the client weights
    client_weights = [client.model.get_weights() for client in clients]

    # Aggregate the client weights on the server
    server.aggregate_weights(client_weights)

# Print the weights of the final model
final_weights = server.model.get_weights()
print("Final Weights:")
for layer_weights in final_weights:
    print(layer_weights)
    print()

# Save the weights to a file
weights_file = 'final_weights.npy'
np.save(weights_file, final_weights)

print("Final weights saved to:", weights_file)
